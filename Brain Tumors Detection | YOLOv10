{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8940125,"sourceType":"datasetVersion","datasetId":5379258},{"sourceId":83907,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":70474,"modelId":95531}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Model Comparison Notebook\n\n## Install Required Libraries\n\n!pip install ultralytics plotly opencv-python-headless torch torchvision transformers albumentations\n!pip install -U ipywidgets\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom sklearn.metrics import accuracy_score\nfrom ultralytics import YOLO\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport yaml\nimport shutil\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T02:43:43.766060Z","iopub.execute_input":"2024-09-20T02:43:43.766440Z","iopub.status.idle":"2024-09-20T02:43:45.500907Z","shell.execute_reply.started":"2024-09-20T02:43:43.766401Z","shell.execute_reply":"2024-09-20T02:43:45.496827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import settings\n\nsettings.update({\"wandb\": False})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths to data directories\ntrain_path = \"/kaggle/input/mri-for-brain-tumor-with-bounding-boxes/Train\"\nval_path = \"/kaggle/input/mri-for-brain-tumor-with-bounding-boxes/Val\"\n# Classes\nclasses = [\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.501833Z","iopub.status.idle":"2024-09-20T02:43:45.502373Z","shell.execute_reply.started":"2024-09-20T02:43:45.502096Z","shell.execute_reply":"2024-09-20T02:43:45.502125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images_from_path(path):\n    images = []\n    filenames = []\n    \n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"The directory {path} does not exist.\")\n    \n    for img_file in os.listdir(path):\n        img_path = os.path.join(path, img_file)\n        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n            img = cv2.imread(img_path)\n            if img is not None:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                images.append(img)\n                filenames.append(img_file)\n            else:\n                print(f\"Failed to load image {img_file}.\")\n    \n    return images, filenames","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.504210Z","iopub.status.idle":"2024-09-20T02:43:45.504741Z","shell.execute_reply.started":"2024-09-20T02:43:45.504448Z","shell.execute_reply":"2024-09-20T02:43:45.504475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_file_lists(directory):\n    images=[]\n    labels=[]\n    for cat in os.listdir(directory):\n        for file in os.listdir(os.path.join(directory,cat,'images')):\n            images.append(os.path.join(directory,cat,'images',file))\n            labels.append(cat)\n    return np.array(images),np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.506294Z","iopub.status.idle":"2024-09-20T02:43:45.506832Z","shell.execute_reply.started":"2024-09-20T02:43:45.506549Z","shell.execute_reply":"2024-09-20T02:43:45.506578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_random_images(img_paths, labels, num_images=10):\n    # Create a subplot with 2 rows and 5 columns\n    _, ax = plt.subplots(2, 5, figsize=(20, 7))\n    \n    # Ensure num_images does not exceed the number of available images\n    num_images = min(num_images, len(img_paths))\n    \n    for i in range(num_images):\n        index = random.randint(0, len(img_paths) - 1)\n        img = cv2.imread(img_paths[index])\n        ax[i // 5, i % 5].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        ax[i // 5, i % 5].set_xlabel(labels[index])\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.508207Z","iopub.status.idle":"2024-09-20T02:43:45.508691Z","shell.execute_reply.started":"2024-09-20T02:43:45.508421Z","shell.execute_reply":"2024-09-20T02:43:45.508445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_train_path_raw,labels_train_raw=get_file_lists(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.509841Z","iopub.status.idle":"2024-09-20T02:43:45.510333Z","shell.execute_reply.started":"2024-09-20T02:43:45.510072Z","shell.execute_reply":"2024-09-20T02:43:45.510097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_random_images(imgs_train_path_raw, labels_train_raw)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.511656Z","iopub.status.idle":"2024-09-20T02:43:45.512145Z","shell.execute_reply.started":"2024-09-20T02:43:45.511886Z","shell.execute_reply":"2024-09-20T02:43:45.511910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths to save preprocessed images\nprocessed_train_path = '/kaggle/working/Train'\nprocessed_val_path = '/kaggle/working/Val'\n\n# Ensure the directories exist\nos.makedirs(processed_train_path, exist_ok=True)\nos.makedirs(processed_val_path, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.513350Z","iopub.status.idle":"2024-09-20T02:43:45.513697Z","shell.execute_reply.started":"2024-09-20T02:43:45.513523Z","shell.execute_reply":"2024-09-20T02:43:45.513542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Define the augmentation pipeline\ntransform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.HueSaturationValue(p=0.5),\n    A.Blur(blur_limit=3, p=0.2),\n    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n    ToTensorV2()\n], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(image, bboxes, class_labels):\n    augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n    img_new = augmented['image']\n    \n    # If img_new is a tensor, convert it to a numpy array\n    if isinstance(img_new, torch.Tensor):\n        img_new = img_new.permute(1, 2, 0).numpy()  # Convert from (C, H, W) to (H, W, C)\n    \n    return img_new, augmented['bboxes'], augmented['class_labels']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load images and labels\ndef preprocess_data(data_path, save_path, isPreprocess=True):\n    for class_label in classes:\n        images_path = os.path.join(data_path, class_label, 'images')\n        save_class_path = os.path.join(save_path, class_label)\n        save_labels_path = os.path.join(save_path, class_label, 'labels')\n        save_images_path = os.path.join(save_path, class_label, 'images')\n        os.makedirs(save_class_path, exist_ok=True)\n        os.makedirs(save_labels_path, exist_ok=True)\n        os.makedirs(save_images_path, exist_ok=True)\n        label_path = os.path.join(data_path, class_label, 'labels')\n        \n        if not os.path.exists(label_path) or not os.listdir(label_path):\n            print(f\"Label path {label_path} does not exist or is empty, skipping class {class_label}.\")\n            continue\n        \n        # Load images and filenames\n        images, filenames = load_images_from_path(images_path)\n        \n        for img, img_file in zip(images, filenames):\n            # Process the corresponding label file if it exists\n            label_file_name = img_file.replace('.jpg', '.txt')\n            label_file_path = os.path.join(label_path, label_file_name)\n            \n            if os.path.exists(label_file_path) and os.path.getsize(label_file_path) > 0:\n                with open(label_file_path, 'r') as file:\n                    label_data = file.readline().strip().split()\n                    if len(label_data) > 0:\n                        class_labels = [int(label_data[0])]\n                        bboxes = [[float(x) for x in label_data[1:]]]\n                        \n                        if isPreprocess:\n                            img_new, bboxes_new, class_labels_new = augment_image(img, bboxes, class_labels)\n                        else:\n                            img_new = img\n                            bboxes_new = bboxes\n                            class_labels_new = class_labels\n                        \n                        save_img_path = os.path.join(save_images_path, img_file)\n                        save_label_path = os.path.join(save_labels_path, label_file_name)\n\n                        # Save image\n                        cv2.imwrite(save_img_path, cv2.cvtColor(img_new, cv2.COLOR_RGB2BGR))\n                        \n                        # Save updated label\n                        with open(save_label_path, 'w') as label_file:\n                            for bbox, label in zip(bboxes_new, class_labels_new):\n                                label_file.write(f\"{label} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\\n\")\n                    else:\n                        print(f\"Label file {label_file_path} is empty, skipping this image.\")\n            else:\n                print(f\"Label file {label_file_path} does not exist or is empty, skipping this image.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.525686Z","iopub.status.idle":"2024-09-20T02:43:45.526313Z","shell.execute_reply.started":"2024-09-20T02:43:45.526066Z","shell.execute_reply":"2024-09-20T02:43:45.526091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess training data\npreprocess_data(train_path, processed_train_path)\npreprocess_data(val_path, processed_val_path, False)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.528033Z","iopub.status.idle":"2024-09-20T02:43:45.528513Z","shell.execute_reply.started":"2024-09-20T02:43:45.528262Z","shell.execute_reply":"2024-09-20T02:43:45.528289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs_train_processed,labels_train_processed=get_file_lists(processed_train_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.530077Z","iopub.status.idle":"2024-09-20T02:43:45.530449Z","shell.execute_reply.started":"2024-09-20T02:43:45.530270Z","shell.execute_reply":"2024-09-20T02:43:45.530291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_random_images(imgs_train_processed,labels_train_processed)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.531918Z","iopub.status.idle":"2024-09-20T02:43:45.532434Z","shell.execute_reply.started":"2024-09-20T02:43:45.532166Z","shell.execute_reply":"2024-09-20T02:43:45.532192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA - Visualize class distribution\ntrain_counts = [len(os.listdir(os.path.join(train_path, cls, 'images'))) for cls in classes]\nval_counts = [len(os.listdir(os.path.join(val_path, cls, 'images'))) for cls in classes]\neda_df = pd.DataFrame({'Class': classes, 'Train': train_counts, 'Validation': val_counts})\n\nfig = go.Figure(data=[\n    go.Bar(name='Train', x=eda_df['Class'], y=eda_df['Train']),\n    go.Bar(name='Validation', x=eda_df['Class'], y=eda_df['Validation'])\n])\nfig.update_layout(barmode='group', title='Class Distribution in Training and Validation Sets')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.534505Z","iopub.status.idle":"2024-09-20T02:43:45.534921Z","shell.execute_reply.started":"2024-09-20T02:43:45.534698Z","shell.execute_reply":"2024-09-20T02:43:45.534721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create YOLOv8 Dataset Configuration File\ndataset_yaml = {\n    'path': '/kaggle/working',\n    'train': 'Train',\n    'val': 'Val',\n    'names': classes\n}\n\nwith open('/kaggle/working/dataset.yaml', 'w') as file:\n    yaml.dump(dataset_yaml, file)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.536090Z","iopub.status.idle":"2024-09-20T02:43:45.536495Z","shell.execute_reply.started":"2024-09-20T02:43:45.536316Z","shell.execute_reply":"2024-09-20T02:43:45.536336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# YOLOv8 Model Training\nyolo_model = YOLO(\"yolov10n.pt\")  # Load a pre-trained YOLOv10 model","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.538268Z","iopub.status.idle":"2024-09-20T02:43:45.539289Z","shell.execute_reply.started":"2024-09-20T02:43:45.539095Z","shell.execute_reply":"2024-09-20T02:43:45.539115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter Tuning\nyolo_model.tune(\n    data=\"/kaggle/working/dataset.yaml\",\n    epochs=30,\n    iterations=10,\n    optimizer=\"AdamW\",\n    plots=False,\n    save=False,\n    val=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.542641Z","iopub.status.idle":"2024-09-20T02:43:45.543130Z","shell.execute_reply.started":"2024-09-20T02:43:45.542873Z","shell.execute_reply":"2024-09-20T02:43:45.542898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load best hyperparameters from the YAML file\nwith open('/kaggle/working/runs/detect/tune/best_hyperparameters.yaml', 'r') as file:\n    best_hyperparameters = yaml.safe_load(file)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.544667Z","iopub.status.idle":"2024-09-20T02:43:45.545356Z","shell.execute_reply.started":"2024-09-20T02:43:45.545086Z","shell.execute_reply":"2024-09-20T02:43:45.545111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use all the best hyperparameters in training\ntrain_result = yolo_model.train(\n    data=\"/kaggle/working/dataset.yaml\",\n    epochs=50,    \n    **best_hyperparameters,  # Unpack all tuned hyperparameters\n    imgsz=640,  \n    save_period=5,\n    split=\"Train\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.546516Z","iopub.status.idle":"2024-09-20T02:43:45.547189Z","shell.execute_reply.started":"2024-09-20T02:43:45.546953Z","shell.execute_reply":"2024-09-20T02:43:45.546977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_images(post_training_files_path, image_files):\n\n    for image_file in image_files:\n        image_path = os.path.join(post_training_files_path, image_file)\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        plt.figure(figsize=(10, 10), dpi=120)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.show()\n\n# List of image files to display\nimage_files = [\n    'confusion_matrix_normalized.png',\n    'F1_curve.png',\n    'P_curve.png',\n    'R_curve.png',\n    'PR_curve.png',\n    'results.png'\n]\n\n# Path to the directory containing the images\npost_training_files_path = '/kaggle/working/runs/detect/train'\n\n# Display the images\ndisplay_images(post_training_files_path, image_files)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_result = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\ntrain_result.tail(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the results.csv file as a pandas dataframe\ntrain_result.columns = train_result.columns.str.strip()\n\n# Create subplots\nfig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n\n# Plot the columns using seaborn\nsns.lineplot(x='epoch', y='train/box_loss', data=train_result, ax=axs[0,0])\nsns.lineplot(x='epoch', y='train/cls_loss', data=train_result, ax=axs[0,1])\nsns.lineplot(x='epoch', y='train/dfl_loss', data=train_result, ax=axs[1,0])\nsns.lineplot(x='epoch', y='metrics/precision(B)', data=train_result, ax=axs[1,1])\nsns.lineplot(x='epoch', y='metrics/recall(B)', data=train_result, ax=axs[2,0])\nsns.lineplot(x='epoch', y='metrics/mAP50(B)', data=train_result, ax=axs[2,1])\nsns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=train_result, ax=axs[3,0])\nsns.lineplot(x='epoch', y='val/box_loss', data=train_result, ax=axs[3,1])\nsns.lineplot(x='epoch', y='val/cls_loss', data=train_result, ax=axs[4,0])\nsns.lineplot(x='epoch', y='val/dfl_loss', data=train_result, ax=axs[4,1])\n\n# Set titles and axis labels for each subplot\naxs[0,0].set(title='Train Box Loss')\naxs[0,1].set(title='Train Class Loss')\naxs[1,0].set(title='Train DFL Loss')\naxs[1,1].set(title='Metrics Precision (B)')\naxs[2,0].set(title='Metrics Recall (B)')\naxs[2,1].set(title='Metrics mAP50 (B)')\naxs[3,0].set(title='Metrics mAP50-95 (B)')\naxs[3,1].set(title='Validation Box Loss')\naxs[4,0].set(title='Validation Class Loss')\naxs[4,1].set(title='Validation DFL Loss')\n\n\nplt.suptitle('Training Metrics and Loss', fontsize=24)\nplt.subplots_adjust(top=0.8)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = yolo_model.val()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final results \nprint(\"precision(B): \", metrics.results_dict[\"metrics/precision(B)\"])\nprint(\"metrics/recall(B): \", metrics.results_dict[\"metrics/recall(B)\"])\nprint(\"metrics/mAP50(B): \", metrics.results_dict[\"metrics/mAP50(B)\"])\nprint(\"metrics/mAP50-95(B): \", metrics.results_dict[\"metrics/mAP50-95(B)\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the YOLOv8 model\nyolo_model.save('/kaggle/working/yolov10_model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.548340Z","iopub.status.idle":"2024-09-20T02:43:45.549003Z","shell.execute_reply.started":"2024-09-20T02:43:45.548750Z","shell.execute_reply":"2024-09-20T02:43:45.548774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_samples(val_images, model, img_size=640):\n    \"\"\"\n    Predict and visualize the results of the YOLOv10 model on multiple samples.\n    \n    Parameters:\n    val_images (list): A list of tuples containing the image and its corresponding class.\n    model (YOLO): The YOLOv10 model used for prediction.\n    img_size (int): The image size to resize the input images (default is 640).\n    \"\"\"\n    # Create a subplot with a dynamic size based on the number of images\n    num_images = len(val_images)\n    cols = 3\n    rows = (num_images // cols) + (num_images % cols > 0)\n    \n    fig, axs = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n    axs = axs.flatten()  # Flatten to access each subplot easily\n    \n    for i, (img, img_class) in enumerate(val_images):\n        # Preprocess image for YOLO input\n        results = model.predict(source=img, save=False)  # Predict with YOLO\n        \n        # Plot the image with bounding boxes\n        axs[i].imshow(img)\n        axs[i].axis('off')\n        axs[i].set_title(f'YOLOv10 Detection - Correct Image Class: {img_class}')\n        \n        # Draw bounding boxes on the image\n        for box in results[0].boxes:\n            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Get coordinates\n            label = classes[int(box.cls[0])]  # Get class label\n            confidence = box.conf[0].cpu().item()  # Get confidence score\n            \n            # Draw a rectangle for the bounding box\n            rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n            axs[i].add_patch(rect)\n            \n            # Add label and confidence score\n            axs[i].text(x1, y1 - 5, f'{label} {confidence:.2f}', color='red', fontsize=10, weight='bold')\n\n    # Hide any remaining empty subplots\n    for j in range(i + 1, len(axs)):\n        axs[j].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images = []\nnum_images_per_class = 2  # Number of images to select from each class\n\nfor class_label in classes:\n    val_images_path = os.path.join(processed_val_path, class_label, 'images')\n    \n    # Load all images from the path\n    img_data, _ = load_images_from_path(val_images_path)\n    \n    # Select up to 'num_images_per_class' images from the loaded data\n    selected_images = img_data[:num_images_per_class]\n    \n    # Create tuples of (image, class_label) for the selected images\n    val_images.extend([(img, class_label) for img in selected_images])","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.550178Z","iopub.status.idle":"2024-09-20T02:43:45.550835Z","shell.execute_reply.started":"2024-09-20T02:43:45.550587Z","shell.execute_reply":"2024-09-20T02:43:45.550610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_samples(val_images, yolo_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T02:43:45.551986Z","iopub.status.idle":"2024-09-20T02:43:45.552640Z","shell.execute_reply.started":"2024-09-20T02:43:45.552383Z","shell.execute_reply":"2024-09-20T02:43:45.552406Z"},"trusted":true},"execution_count":null,"outputs":[]}]}